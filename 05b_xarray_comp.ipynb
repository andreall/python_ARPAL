{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computations and Masks with Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106d05e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the monthly sea surface temperature (SST) data from the Community Earth System Model v2 (CESM2), which is a Global Climate Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cookie file cannot be read and written: /home/aliraloarca/.cookies\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -37] NetCDF: Write to read only: b'https://my.cmems-du.eu/thredds/dodsC/cmems_mod_glo_phy_my_0.083_P1M-m'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/file_manager.py:209\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key]\n\u001b[1;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[key]\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('https://my.cmems-du.eu/thredds/dodsC/cmems_mod_glo_phy_my_0.083_P1M-m',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '83b15ec5-86c1-4055-8c20-d3a4f1662bbd']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/aliraloarca/Library/CloudStorage/OneDrive-unige.it/Consulting/2023 ARPAL corso/python_ARPAL/05b_xarray_comp.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aliraloarca/Library/CloudStorage/OneDrive-unige.it/Consulting/2023%20ARPAL%20corso/python_ARPAL/05b_xarray_comp.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ds \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39;49mopen_dataset(\u001b[39m'\u001b[39;49m\u001b[39mhttps://my.cmems-du.eu/thredds/dodsC/cmems_mod_glo_phy_my_0.083_P1M-m\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/api.py:540\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m decoders \u001b[39m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    529\u001b[0m     decode_cf,\n\u001b[1;32m    530\u001b[0m     open_backend_dataset_parameters\u001b[39m=\u001b[39mbackend\u001b[39m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m     decode_coords\u001b[39m=\u001b[39mdecode_coords,\n\u001b[1;32m    537\u001b[0m )\n\u001b[1;32m    539\u001b[0m overwrite_encoded_chunks \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39moverwrite_encoded_chunks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 540\u001b[0m backend_ds \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mopen_dataset(\n\u001b[1;32m    541\u001b[0m     filename_or_obj,\n\u001b[1;32m    542\u001b[0m     drop_variables\u001b[39m=\u001b[39;49mdrop_variables,\n\u001b[1;32m    543\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdecoders,\n\u001b[1;32m    544\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    545\u001b[0m )\n\u001b[1;32m    546\u001b[0m ds \u001b[39m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    547\u001b[0m     backend_ds,\n\u001b[1;32m    548\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    558\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:572\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_dataset\u001b[39m(\n\u001b[1;32m    552\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    553\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m     autoclose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m ):\n\u001b[1;32m    571\u001b[0m     filename_or_obj \u001b[39m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 572\u001b[0m     store \u001b[39m=\u001b[39m NetCDF4DataStore\u001b[39m.\u001b[39;49mopen(\n\u001b[1;32m    573\u001b[0m         filename_or_obj,\n\u001b[1;32m    574\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    575\u001b[0m         \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    576\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    577\u001b[0m         clobber\u001b[39m=\u001b[39;49mclobber,\n\u001b[1;32m    578\u001b[0m         diskless\u001b[39m=\u001b[39;49mdiskless,\n\u001b[1;32m    579\u001b[0m         persist\u001b[39m=\u001b[39;49mpersist,\n\u001b[1;32m    580\u001b[0m         lock\u001b[39m=\u001b[39;49mlock,\n\u001b[1;32m    581\u001b[0m         autoclose\u001b[39m=\u001b[39;49mautoclose,\n\u001b[1;32m    582\u001b[0m     )\n\u001b[1;32m    584\u001b[0m     store_entrypoint \u001b[39m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    585\u001b[0m     \u001b[39mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:376\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    370\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    371\u001b[0m     clobber\u001b[39m=\u001b[39mclobber, diskless\u001b[39m=\u001b[39mdiskless, persist\u001b[39m=\u001b[39mpersist, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m manager \u001b[39m=\u001b[39m CachingFileManager(\n\u001b[1;32m    374\u001b[0m     netCDF4\u001b[39m.\u001b[39mDataset, filename, mode\u001b[39m=\u001b[39mmode, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(manager, group\u001b[39m=\u001b[39;49mgroup, mode\u001b[39m=\u001b[39;49mmode, lock\u001b[39m=\u001b[39;49mlock, autoclose\u001b[39m=\u001b[39;49mautoclose)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:323\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group \u001b[39m=\u001b[39m group\n\u001b[1;32m    322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mds\u001b[39m.\u001b[39mdata_model\n\u001b[1;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mfilepath()\n\u001b[1;32m    325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_remote \u001b[39m=\u001b[39m is_remote_uri(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mds\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:379\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39macquire_context(needs_lock) \u001b[39mas\u001b[39;00m root:\n\u001b[1;32m    380\u001b[0m         ds \u001b[39m=\u001b[39m _nc4_require_group(root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode)\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/file_manager.py:197\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire_context\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     file, cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    198\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xarray/backends/file_manager.py:215\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    213\u001b[0m     kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[0;32m--> 215\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opener(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    217\u001b[0m     \u001b[39m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:2358\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:1926\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -37] NetCDF: Write to read only: b'https://my.cmems-du.eu/thredds/dodsC/cmems_mod_glo_phy_my_0.083_P1M-m'"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset('https://my.cmems-du.eu/thredds/dodsC/cmems_mod_glo_phy_my_0.083_P1M-m')\n",
    "#ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Arithmetic Operations\n",
    "\n",
    "Arithmetic operations with a single DataArray automatically apply over all array values (like NumPy). This process is called vectorization.  Let's convert the air temperature from degrees Celsius to kelvins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos + 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets's square all values in `tos`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregation Methods \n",
    "\n",
    "A very common step during data analysis is to summarize the data in question by computing aggregations like `sum()`, `mean()`, `median()`, `min()`, `max()` in which reduced data provide insight into the nature of large dataset. Let's explore some of these aggregation methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we specified no `dim` argument the function was applied over all dimensions, computing the mean of every element of `tos` across time and space. It is possible to specify a dimension along which to compute an aggregation. For example, to calculate the mean in time for all locations, specify the time dimension as the dimension along which the mean should be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.mean(dim='time').plot(size=7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the temporal min:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.min(dim=['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the spatial sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.sum(dim=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the temporal median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.median(dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes some other built-in xarray aggregations:\n",
    "\n",
    "| Aggregation              | Description                     |\n",
    "|--------------------------|---------------------------------|\n",
    "| ``count()``              | Total number of items           |\n",
    "| ``mean()``, ``median()`` | Mean and median                 |\n",
    "| ``min()``, ``max()``     | Minimum and maximum             |\n",
    "| ``std()``, ``var()``     | Standard deviation and variance |\n",
    "| ``prod()``               | Compute product of elements            |\n",
    "| ``sum()``                | Compute sum of elements                |\n",
    "| ``argmin()``, ``argmax()``| Find index of minimum and maximum value |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GroupBy: Split, Apply, Combine\n",
    "\n",
    "Simple aggregations can give useful summary of our dataset, but often we would prefer to aggregate conditionally on some coordinate labels or groups. Xarray provides the so-called `groupby` operation which enables the **split-apply-combine** workflow on xarray DataArrays and Datasets. The split-apply-combine operation is illustrated in this figure\n",
    "\n",
    "<img src=\"./images/xarray-split-apply-combine.jpeg\">\n",
    "\n",
    "This makes clear what the `groupby` accomplishes:\n",
    "\n",
    "- The split step involves breaking up and grouping an xarray Dataset or DataArray depending on the value of the specified group key.\n",
    "- The apply step involves computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n",
    "- The combine step merges the results of these operations into an output xarray Dataset or DataArray.\n",
    "\n",
    "We are going to use `groupby` to remove the seasonal cycle (\"climatology\") from our dataset. See the [xarray `groupby` user guide](https://xarray.pydata.org/en/stable/user-guide/groupby.html) for more examples of what `groupby` can take as an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's select a gridpoint closest to a specified lat-lon, and plot a time series of SST at that point. The annual cycle will be quite evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.sel(lon=310, lat=50, method='nearest').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split\n",
    "\n",
    "Let's group data by month, i.e. all Januaries in one group, all Februaries in one group, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.groupby(ds.time.dt.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "\n",
    "In the above code, we are using the `.dt` [`DatetimeAccessor`](https://xarray.pydata.org/en/stable/generated/xarray.core.accessor_dt.DatetimeAccessor.html) to extract specific components of dates/times in our time coordinate dimension. For example, we can extract the year with `ds.time.dt.year`. See also the equivalent [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html).\n",
    "    \n",
    "   </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray also offers a more concise syntax when the variable you’re grouping on is already present in the dataset. This is identical to `ds.tos.groupby(ds.time.dt.month)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.groupby('time.month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply & Combine \n",
    "\n",
    "Now that we have groups defined, it’s time to “apply” a calculation to the group. These calculations can either be:\n",
    "\n",
    "- aggregation: reduces the size of the group\n",
    "- transformation: preserves the group’s full size\n",
    "\n",
    "At then end of the apply step, xarray will automatically combine the aggregated/transformed groups back into a single object. \n",
    "\n",
    "\n",
    "\n",
    "#### Compute climatology \n",
    "\n",
    "\n",
    "Let's calculate the climatology at every point in the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_clim = ds.tos.groupby('time.month').mean()\n",
    "tos_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot climatology at a specific point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_clim.sel(lon=310, lat=50, method='nearest').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot zonal mean climatology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_clim.mean(dim='lon').transpose().plot.contourf(levels=12, cmap='turbo');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and plot the difference between January and December climatologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tos_clim.sel(month=1) - tos_clim.sel(month=12)).plot(size=6, robust=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute anomaly\n",
    "\n",
    "Now let's combine the previous steps to compute climatology and use xarray's `groupby` arithmetic to remove this climatology from our original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ds.tos.groupby('time.month')\n",
    "tos_anom = gb - gb.mean(dim='time')\n",
    "tos_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_anom.sel(lon=310, lat=50, method='nearest').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute and visualize the mean global anomaly over time. We need to specify both `lat` and `lon` dimensions in the `dim` argument to `mean()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_mean_global_anom = tos_anom.mean(dim=['lat', 'lon'])\n",
    "unweighted_mean_global_anom.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "   \n",
    "\n",
    "An operation which combines grid cells of different size is not scientifically valid unless each cell is weighted by the size of the grid cell. Xarray has a convenient [`.weighted()`](https://xarray.pydata.org/en/stable/user-guide/computation.html#weighted-array-reductions) method to accomplish this\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the cell area data from another CESM2 dataset that contains the weights for the grid cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath2 = DATASETS.fetch('CESM2_grid_variables.nc')\n",
    "areacello = xr.open_dataset(filepath2).areacello\n",
    "areacello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's calculate area-weighted mean global anomaly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean_global_anom = tos_anom.weighted(areacello).mean(dim=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot both unweighted and weighted means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_mean_global_anom.plot(size=7)\n",
    "weighted_mean_global_anom.plot()\n",
    "plt.legend(['unweighted', 'weighted']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other high level computation functionality\n",
    "\n",
    "- `resample`: [Groupby-like functionality specifialized for time dimensions. Can be used for temporal upsampling and downsampling](https://xarray.pydata.org/en/stable/user-guide/time-series.html#resampling-and-grouped-operations)\n",
    "- `rolling`: [Useful for computing aggregations on moving windows of your dataset e.g. computing moving averages](https://xarray.pydata.org/en/stable/user-guide/computation.html#rolling-window-operations)\n",
    "- `coarsen`: [Generic functionality for downsampling data](https://xarray.pydata.org/en/stable/user-guide/computation.html#coarsen-large-arrays)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, resample to annual frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ds.tos.resample(time='AS')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a 5-month moving average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_avg = ds.tos.rolling(time=5, center=True).mean()\n",
    "m_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 50\n",
    "lon = 310\n",
    "\n",
    "m_avg.isel(lat=lat, lon=lon).plot(size=6)\n",
    "ds.tos.isel(lat=lat, lon=lon).plot()\n",
    "plt.legend(['5-month moving average', 'monthly data']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Masking Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using the `xr.where()` or `.where()` method, elements of an xarray Dataset or xarray DataArray that satisfy a given condition or multiple conditions can be replaced/masked. To demonstrate this, we are going to use the `.where()` method on the `tos` DataArray. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same sea surface temperature dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `where` with one condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we wish to analyze just the last time in the dataset. We could of course use `.isel()` for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ds.tos.isel(time=-1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `.isel()` and `.sel()` that change the shape of the returned results, `.where()` preserves the shape of the original data. It accomplishes this by returning values from the original DataArray or Dataset if the `condition` is `True`, and fills in values (by default `nan`) wherever the `condition` is `False`. \n",
    "\n",
    "Before applying it, let's look at the [`.where()` documentation](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.where.html). As the documention points out, the conditional expression in `.where()` can be: \n",
    "\n",
    "- a DataArray\n",
    "- a Dataset\n",
    "- a function\n",
    "\n",
    "For demonstration purposes, let's use `.where()` to mask locations with temperature values greater than `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sample = sample.where(sample < 0.0)\n",
    "masked_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot both our original sample, and the masked sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(19, 6))\n",
    "sample.plot(ax=axes[0])\n",
    "masked_sample.plot(ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using `where` with multiple conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.where()` allows providing multiple conditions. To do this, we need to make sure each conditional expression is enclosed in `()`. To combine conditions, we use the `bit-wise and` (`&`) operator and/or the `bit-wise or` (`|`). Let's use `.where()` to mask locations with temperature values less than 25 and greater than 30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.where((sample > 25) & (sample < 30)).plot(size=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use coordinates to apply a mask as well. Below, we use the `latitude` and `longitude` coordinates to mask everywhere outside of the [Niño 3.4 region](https://www.ncdc.noaa.gov/teleconnections/enso/indicators/sst/):\n",
    "\n",
    "![](https://www.ncdc.noaa.gov/monitoring-content/teleconnections/nino-regions.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.where(\n",
    "    (sample.lat < 5) & (sample.lat > -5) & (sample.lon > 190) & (sample.lon < 240)\n",
    ").plot(size=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `where` with a custom fill value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.where()` can take a second argument, which, if supplied, defines a fill value for the masked region. Below we fill masked regions with a constant `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.where((sample > 25) & (sample < 30), 0).plot(size=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and References\n",
    "\n",
    "- `groupby`: [Useful for binning/grouping data and applying reductions and/or transformations on those groups](https://xarray.pydata.org/en/stable/user-guide/groupby.html)\n",
    "- `resample`: [Groupby-like functionality specifialized for time dimensions. Can be used for temporal upsampling and downsampling](https://xarray.pydata.org/en/stable/user-guide/time-series.html#resampling-and-grouped-operations)\n",
    "- `rolling`: [Useful for computing aggregations on moving windows of your dataset e.g. computing moving averages](https://xarray.pydata.org/en/stable/user-guide/computation.html#rolling-window-operations)\n",
    "- `coarsen`: [Generic functionality for downsampling data](https://xarray.pydata.org/en/stable/user-guide/computation.html#coarsen-large-arrays)\n",
    "\n",
    "- `weighted`: [Useful for weighting data before applying reductions](https://xarray.pydata.org/en/stable/user-guide/computation.html#weighted-array-reductions)\n",
    "\n",
    "- [More xarray tutorials and videos](https://xarray.pydata.org/en/stable/tutorials-and-videos.html)\n",
    "- [Xarray Documentation - Masking with `where()`](https://xarray.pydata.org/en/stable/user-guide/indexing.html#masking-with-where)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
